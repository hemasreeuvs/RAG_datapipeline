
    Retrieval-Augmented Generation (RAG) is an architectural framework designed to enhance the accuracy and reliability of Large Language Models (LLMs) by grounding them in external, authoritative knowledge bases. While standard models rely strictly on the data they were originally trained on—which can lead to outdated information or "hallucinations"—RAG enables a model to look up fresh data before generating a response. This process involves retrieving relevant document snippets from a source like a private database or the live web, and then passing that context into the model alongside the user’s original question.